{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgsUQPqQZH0OQ1zCUvuofT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HappyplaceAI/jupyter/blob/master/corona.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXdAhd-MwIJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0516f040-52cc-4c25-f248-4b539ac628bb"
      },
      "source": [
        "# install chromium, its driver, and selenium\n",
        "#!apt install chromium-chromedriver\n",
        "#!pip install selenium\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# open it, go to a website, and get results\n",
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "wd.get(\"https://www.google.com\")\n",
        "print(wd.title)  # results\n",
        "# divs = wd.find_elements_by_css_selector('div')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Google\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ss17gafJC3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pandas as pd\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "import os \n",
        "import os.path\n",
        "import csv \n",
        "import datetime\n",
        "import random\n",
        "from getpass import getpass\n",
        "import time\n",
        "import random   \n",
        "from dateutil import parser\n",
        "import calendar\n",
        "\n",
        "from urllib.request import Request, urlopen\n",
        "from fake_useragent import UserAgent\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "idx = datetime.date.today()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#********************************************\n",
        "\n",
        "topic = \"coronavirus\"\n",
        "keyword = \"Coronavirus India\"\n",
        "\n",
        "website = \"https://www.google.com\"\n",
        "browser = webdriver.Chrome('chromedriver',options=options)\n",
        "browser.get(website)\n",
        "\n",
        "browser.maximize_window()\n",
        "\n",
        "\n",
        "\n",
        "def writerows(rows, filename):\n",
        "    with open(filename, 'a', encoding='utf-8') as toWrite:\n",
        "        writer = csv.writer(toWrite)\n",
        "        writer.writerows([rows])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11LL5p5rJNIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrapePage(keyword,rank):\n",
        "    soup = BeautifulSoup(browser.page_source,\"html.parser\")\n",
        "    result_block = soup.find_all('div', attrs={'class': 'g'})\n",
        "    for r in result_block:\n",
        "    \n",
        "        link = r.find('a', href=True)\n",
        "        title = r.find('h3')\n",
        "        description = r.find('span', attrs={'class': 'st'})\n",
        "        if r.find(class_=\"f\"):\n",
        "            res = r.find(class_=\"f\").text\n",
        "        else:\n",
        "            res = \"-1\"\n",
        "\n",
        "        if link and title and description:\n",
        "            link = link['href']\n",
        "            title = title.get_text().strip()\n",
        "            if description:\n",
        "                description = description.get_text().strip()\n",
        "            if link != '#':\n",
        "                rank += 1\n",
        "           \n",
        "            row = [keyword,rank,title,res,description,link]\n",
        "            print(row)\n",
        "            print(30*\"--\")\n",
        "            writerows(row,outputFile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47FKiPnSJSpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "899844d2-2b2f-4239-86d0-ac46ff2401c3"
      },
      "source": [
        "outputFile = \"C:/CART/{}_{}.csv\".format(topic.title().replace(\" \",\"\"),idx)\n",
        "print(outputFile)\n",
        "\n",
        "\n",
        "\n",
        "time.sleep(random.randint(1,100)/50)\n",
        "\n",
        "search = browser.find_element_by_class_name(\"gLFyf\")\n",
        "search.clear()\n",
        "search.send_keys(keyword)\n",
        "search.send_keys(Keys.RETURN);\n",
        "time.sleep(random.randint(40,100)/50)\n",
        "soup = BeautifulSoup(browser.page_source,\"html.parser\")\n",
        "time.sleep(random.randint(40,100)/50)\n",
        "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "count = 0\n",
        "\n",
        "    \n",
        "search = browser.find_element_by_class_name(\"gLFyf\")\n",
        "search.clear()\n",
        "search.send_keys(keyword)\n",
        "search.send_keys(Keys.RETURN);\n",
        "\n",
        "time.sleep(random.randint(1,100)/50)\n",
        "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    \n",
        "noPages = int(soup.findAll(\"a\", class_=\"fl\")[-1].text)\n",
        "for i in range(noPages):\n",
        "   \n",
        "    browser.find_element_by_id(\"pnnext\").click()\n",
        "    time.sleep(random.randint(25,100)/25)\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    count += 1\n",
        "    scrapePage(keyword,count)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:/CART/Coronavirus_2020-02-04.csv\n",
            "['Coronavirus India', 2, 'Coronavirus impact on Indian economy, according to Maruti ...', '1 day ago - ', \"1 day ago - The new coronavirus outbreak is unlikely to have a serious impact on India's struggling auto sector even as factories remain shuttered in China\\xa0...\", 'https://www.cnbc.com/2020/02/03/coronavirus-impact-on-indian-economy-according-to-maruti-chief.html']\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-4be0789db547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"window.scrollTo(0, document.body.scrollHeight);\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mscrapePage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-b0c71567e274>\u001b[0m in \u001b[0;36mscrapePage\u001b[0;34m(keyword, rank)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-eec72c5eaf87>\u001b[0m in \u001b[0;36mwriterows\u001b[0;34m(rows, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtoWrite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoWrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/CART/Coronavirus_2020-02-04.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtFYWumgJZeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Source'] = df['Link'].apply(lambda x: x.split(\"//\")[1].split(\"/\")[0])\n",
        "excl = ['books.google.com.in']\n",
        "df= df[~df['Source'].isin(excl)]\n",
        "print(df.shape)\n",
        "\n",
        "print(df['Source'].value_counts())\n",
        "#df[df['Source']==\"forum.lowyat.net\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EztoozHJJhfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"C:/CART/{}_prep_{}.csv\".format(topic.title().replace(\" \",\"\"),idx),encoding=\"utf-8\",index=None)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU27fiNjJoQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.collocations import *\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "# modules for generating the word cloud\n",
        "from os import path, getcwd\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, ImageColorGenerator\n",
        "#tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmHwy8v-JpPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "field =\"Description\"\n",
        "\n",
        "df[field] = df[field].astype(str)\n",
        "df[field] = df[field].apply(lambda x: x.lower())\n",
        "print(len(df[field].str.cat(sep=', ')))\n",
        "\n",
        "#All property Description\n",
        "print(\"concat desc\")\n",
        "df[field] = df[field].astype(str)\n",
        "df[field] = df[field].apply(lambda x: x.lower())\n",
        "tw = df[field].str.cat(sep=', ')\n",
        "print('concat length',len(tw))\n",
        "\n",
        "\n",
        "tw  = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', tw, flags=re.MULTILINE)\n",
        "tw = re.sub(r'[^a-zA-Z\\s]', ' ', tw)\n",
        "tw = tw.replace(\"netflix\",\"\").replace(\"hahaha\",\"\").replace(\"hahah\",\"\").replace(\"haha\",\"\")\n",
        "\n",
        "#tw = re.sub(r'[^a-zA-Z0-9\\s]', ' ', tw)\n",
        "#tw = re.sub(r'[\\W_]', ' ', tw)\n",
        "\n",
        "\n",
        "tok_text = tokenizer.tokenize(tw)\n",
        "print('tokenize length',len(tok_text))\n",
        "\n",
        "#remove stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "malayStopWords =['di','pada','kat',\"ke\",\"ko\",\"ye\"]\n",
        "word_set = set(w for w in tok_text if w.lower() not in stopwords)\n",
        "print('length after english stop words',len(word_set))\n",
        "word_set = set(w for w in word_set if w.lower() not in malayStopWords)\n",
        "print('length after malay stop words',len(word_set))\n",
        "print(len(word_set))\n",
        "\n",
        "#get topwords and leastwords\n",
        "word_count_dict = Counter(w.lower() for w in word_set)\n",
        "w = word_count_dict.most_common()\n",
        "print(len(w))\n",
        "w = pd.DataFrame(w)\n",
        "w = w.rename(columns={0:'word',1:'count'})\n",
        "desc = w[~w.word.str.match('^\\-?(\\d*\\.?\\d+|\\d+\\.?\\d*)$')]\n",
        "#remove top words\n",
        "topWord = list(desc[:10][\"word\"])\n",
        "print(list(desc[:100][\"word\"]))\n",
        "#leastWord = list(desc[desc['count']==1][\"word\"])\n",
        "\n",
        "#word_set = [x for x in word_set if x not in leastWord]\n",
        "\n",
        "\n",
        "text = ' '.join(word_set).lower()\n",
        "\n",
        "print(\"done.....................\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9D_AmRjJwbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from scipy.misc import imread\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "                       width = 1500, height=1500,\n",
        "                      stopwords=STOPWORDS,\n",
        "                      background_color='black',\n",
        "                      #mask=imread('C:/Users/Faizal/Anaconda3/my_map2/lib/images/train.png'),\n",
        "                     ).generate(text)\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "plt.title(keyword, color=\"grey\", size=25, y=1.01)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "#plt.text(x = 0, y = 1450, fontsize = 15, alpha = 1,color = 'white',  s = \" www.redangpow.com \", backgroundcolor=\"grey\")\n",
        "plt.savefig('F:/RAP Cares/{}_{}.png'.format(topic.title().replace(\" \",\"\"),idx), transparent=True, bbox_inches='tight',papertype = 'a4')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69gBaKgnJ2d8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "ngr = ngrams(tok_text, 5)\n",
        "ng = collections.Counter(ngr).most_common()\n",
        "ng = pd.DataFrame(ng)\n",
        "ng.columns = [\"Phrase\",\" Count\"]\n",
        "ng[\"Phrase\"] = ng[\"Phrase\"].apply(lambda x: \" \".join(x))\n",
        "ng[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4UntvIZJ5X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngr = ngrams(tok_text, 4)\n",
        "ng = collections.Counter(ngr).most_common()\n",
        "ng = pd.DataFrame(ng)\n",
        "ng.columns = [\"Phrase\",\" Count\"]\n",
        "ng[\"Phrase\"] = ng[\"Phrase\"].apply(lambda x: \" \".join(x))\n",
        "ng[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg1fa9ftJ6Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngr = ngrams(tok_text, 3)\n",
        "ng = collections.Counter(ngr).most_common()\n",
        "ng = pd.DataFrame(ng)\n",
        "ng.columns = [\"Phrase\",\" Count\"]\n",
        "\n",
        "ng[\"Phrase\"] = ng[\"Phrase\"].apply(lambda x: \" \".join(x))\n",
        "ng[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YC63r7BJ_e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngr = ngrams(tok_text, 2)\n",
        "ng = collections.Counter(ngr).most_common()\n",
        "ng = pd.DataFrame(ng)\n",
        "ng.columns = [\"Phrase\",\" Count\"]\n",
        "ng[\"Phrase\"] = ng[\"Phrase\"].apply(lambda x: \" \".join(x))\n",
        "ng[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dPP97jvKDws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ngr = ngrams(tok_text, 1)\n",
        "ng = collections.Counter(ngr).most_common()\n",
        "ng = pd.DataFrame(ng)\n",
        "ng.columns = [\"Phrase\",\" Count\"]\n",
        "ng[\"Phrase\"] = ng[\"Phrase\"].apply(lambda x: \" \".join(x))\n",
        "ng[:20]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}